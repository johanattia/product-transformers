# tf-saint
TensorFlow implementation of **S**elf-**A**ttention and **In**tersample Attention **T**ransformer from [SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training](https://arxiv.org/pdf/2106.01342.pdf).

![Self-Attention and Intersample Attention Transformer](image/SAINT.png "Self-Attention and Intersample Attention Transformer")

Please find [here](https://github.com/somepago/saint) the original PyTorch implementation of article authors.

## License
[MIT License](LICENSE)
