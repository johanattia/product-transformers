# tensorflow-saint
TensorFlow implementation of Self-Attention and Intersample Attention Transformer (SAINT) for tabular data, including self-supervised pre-training and supervised training. For more details, see the original paper on [arXiv](https://arxiv.org/pdf/2106.01342.pdf): *SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training*.

## About SAINT
Below a visual description of the learning framework from the original article:

![Self-Attention and Intersample Attention Transformer](image/SAINT.png "Self-Attention and Intersample Attention Transformer")

## License
[MIT License](LICENSE)
