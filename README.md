# tensorflow-saint
TensorFlow implementation of Self-Attention and Intersample Attention Transformer (SAINT) for tabular data, including self-supervised pre-training and supervised training. 

Below a visual description of the learning framework from the original article *SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training* (https://arxiv.org/pdf/2106.01342.pdf)

![Self-Attention and Intersample Attention Transformer](image/SAINT.png "Self-Attention and Intersample Attention Transformer")

## License
[MIT License](LICENSE)
